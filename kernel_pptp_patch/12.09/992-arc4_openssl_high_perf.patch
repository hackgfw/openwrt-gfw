--- a/crypto/arc4.c
+++ b/crypto/arc4.c
@@ -30,22 +30,32 @@ static int arc4_set_key(struct crypto_tf
 			unsigned int key_len)
 {
 	struct arc4_ctx *ctx = crypto_tfm_ctx(tfm);
-	int i, j = 0, k = 0;
+	register u32 tmp;
+	register u32 * d;
+	register int id1, id2;
+	unsigned int i;
 
-	ctx->x = 1;
+	ctx->x = 0;
 	ctx->y = 0;
+	d=ctx->S;
+	id1=id2=0;
 
-	for (i = 0; i < 256; i++)
-		ctx->S[i] = i;
 
-	for (i = 0; i < 256; i++) {
-		u32 a = ctx->S[i];
-		j = (j + in_key[k] + a) & 0xff;
-		ctx->S[i] = ctx->S[j];
-		ctx->S[j] = a;
-		if (++k >= key_len)
-			k = 0;
-	}
+#define SK_LOOP(d,n) { \
+		tmp=d[(n)]; \
+		id2 = (in_key[id1] + tmp + id2) & 0xff; \
+		if (++id1 == key_len) id1=0; \
+		d[(n)]=d[id2]; \
+		d[id2]=tmp; }
+
+	for (i=0; i < 256; i++) d[i]=i;
+	for (i=0; i < 256; i+=4)
+		{
+		SK_LOOP(d,i+0);
+		SK_LOOP(d,i+1);
+		SK_LOOP(d,i+2);
+		SK_LOOP(d,i+3);
+		}
 
 	return 0;
 }
@@ -53,38 +63,251 @@ static int arc4_set_key(struct crypto_tf
 static void arc4_crypt(struct arc4_ctx *ctx, u8 *out, const u8 *in,
 		       unsigned int len)
 {
-	u32 *const S = ctx->S;
-	u32 x, y, a, b;
-	u32 ty, ta, tb;
+	register u32 *const d = ctx->S;
+	register  u32 x, y, tx, ty;
+	size_t i;
 
 	if (len == 0)
 		return;
 
 	x = ctx->x;
 	y = ctx->y;
+#define RC4_CHUNK unsigned long
+#if defined(RC4_CHUNK)
+        /*
+         * The original reason for implementing this(*) was the fact that
+         * pre-21164a Alpha CPUs don't have byte load/store instructions
+         * and e.g. a byte store has to be done with 64-bit load, shift,
+         * and, or and finally 64-bit store. Peaking data and operating
+         * at natural word size made it possible to reduce amount of
+         * instructions as well as to perform early read-ahead without
+         * suffering from RAW (read-after-write) hazard. This resulted
+         * in ~40%(**) performance improvement on 21064 box with gcc.
+         * But it's not only Alpha users who win here:-) Thanks to the
+         * early-n-wide read-ahead this implementation also exhibits
+         * >40% speed-up on SPARC and 20-30% on 64-bit MIPS (depending
+         * on sizeof(RC4_INT)).
+         *
+         * (*)  "this" means code which recognizes the case when input
+         *      and output pointers appear to be aligned at natural CPU
+         *      word boundary
+         * (**) i.e. according to 'apps/openssl speed rc4' benchmark,
+         *      crypto/rc4/rc4speed.c exhibits almost 70% speed-up...
+         *
+         * Cavets.
+         *
+         * - RC4_CHUNK="unsigned long long" should be a #1 choice for
+         *   UltraSPARC. Unfortunately gcc generates very slow code
+         *   (2.5-3 times slower than one generated by Sun's WorkShop
+         *   C) and therefore gcc (at least 2.95 and earlier) should
+         *   always be told that RC4_CHUNK="unsigned long".
+         *
+         *                                      <appro@fy.chalmers.se>
+         */
+
+# define RC4_STEP       ( \
+                        x=(x+1) &0xff,  \
+                        tx=d[x],        \
+                        y=(tx+y)&0xff,  \
+                        ty=d[y],        \
+                        d[y]=tx,        \
+                        d[x]=ty,        \
+                        (RC4_CHUNK)d[(tx+ty)&0xff]\
+                        )
+
+        if ( ( ((size_t)in  & (sizeof(RC4_CHUNK)-1)) |
+               ((size_t)out & (sizeof(RC4_CHUNK)-1)) ) == 0 )
+                {
+                RC4_CHUNK ichunk,otp;
+                const union { long one; char little; } is_endian = {1};
+
+                /*
+                 * I reckon we can afford to implement both endian
+                 * cases and to decide which way to take at run-time
+                 * because the machine code appears to be very compact
+                 * and redundant 1-2KB is perfectly tolerable (i.e.
+                 * in case the compiler fails to eliminate it:-). By
+                 * suggestion from Terrel Larson <terr@terralogic.net>
+                 * who also stands for the is_endian union:-)
+                 *
+                 * Special notes.
+                 *
+                 * - is_endian is declared automatic as doing otherwise
+                 *   (declaring static) prevents gcc from eliminating
+                 *   the redundant code;
+                 * - compilers (those I've tried) don't seem to have
+                 *   problems eliminating either the operators guarded
+                 *   by "if (sizeof(RC4_CHUNK)==8)" or the condition
+                 *   expressions themselves so I've got 'em to replace
+                 *   corresponding #ifdefs from the previous version;
+                 * - I chose to let the redundant switch cases when
+                 *   sizeof(RC4_CHUNK)!=8 be (were also #ifdefed
+                 *   before);
+                 * - in case you wonder "&(sizeof(RC4_CHUNK)*8-1)" in
+                 *   [LB]ESHFT guards against "shift is out of range"
+                 *   warnings when sizeof(RC4_CHUNK)!=8
+                 *
+                 *                      <appro@fy.chalmers.se>
+                 */
+                if (!is_endian.little)
+                        {       /* BIG-ENDIAN CASE */
+# define BESHFT(c)      (((sizeof(RC4_CHUNK)-(c)-1)*8)&(sizeof(RC4_CHUNK)*8-1))
+                        for (;len&(0-sizeof(RC4_CHUNK));len-=sizeof(RC4_CHUNK))
+                                {
+                                ichunk  = *(RC4_CHUNK *)in;
+                                otp  = RC4_STEP<<BESHFT(0);
+                                otp |= RC4_STEP<<BESHFT(1);
+                                otp |= RC4_STEP<<BESHFT(2);
+                                otp |= RC4_STEP<<BESHFT(3);
+                                if (sizeof(RC4_CHUNK)==8)
+                                        {
+                                        otp |= RC4_STEP<<BESHFT(4);
+                                        otp |= RC4_STEP<<BESHFT(5);
+                                        otp |= RC4_STEP<<BESHFT(6);
+                                        otp |= RC4_STEP<<BESHFT(7);
+                                        }
+                                *(RC4_CHUNK *)out = otp^ichunk;
+                                in  += sizeof(RC4_CHUNK);
+                                out += sizeof(RC4_CHUNK);
+                                }
+                        if (len)
+                                {
+                                RC4_CHUNK mask=(RC4_CHUNK)-1, ochunk;
+
+                                ichunk = *(RC4_CHUNK *)in;
+                                ochunk = *(RC4_CHUNK *)out;
+                                otp = 0;
+                                i = BESHFT(0);
+                                mask <<= (sizeof(RC4_CHUNK)-len)<<3;
+                                switch (len&(sizeof(RC4_CHUNK)-1))
+                                        {
+                                        case 7: otp  = RC4_STEP<<i, i-=8;
+                                        case 6: otp |= RC4_STEP<<i, i-=8;
+                                        case 5: otp |= RC4_STEP<<i, i-=8;
+                                        case 4: otp |= RC4_STEP<<i, i-=8;
+                                        case 3: otp |= RC4_STEP<<i, i-=8;
+                                        case 2: otp |= RC4_STEP<<i, i-=8;
+                                        case 1: otp |= RC4_STEP<<i, i-=8;
+                                        case 0: ; /*
+                                                   * it's never the case,
+                                                   * but it has to be here
+                                                   * for ultrix?
+                                                   */
+                                        }
+                                ochunk &= ~mask;
+                                ochunk |= (otp^ichunk) & mask;
+                                *(RC4_CHUNK *)out = ochunk;
+                                }
+                        ctx->x=x;
+                        ctx->y=y;
+                        return;
+                        }
+                else
+                        {       /* LITTLE-ENDIAN CASE */
+# define LESHFT(c)      (((c)*8)&(sizeof(RC4_CHUNK)*8-1))
+                        for (;len&(0-sizeof(RC4_CHUNK));len-=sizeof(RC4_CHUNK))
+                                {
+                                ichunk  = *(RC4_CHUNK *)in;
+                                otp  = RC4_STEP;
+                                otp |= RC4_STEP<<8;
+                                otp |= RC4_STEP<<16;
+                                otp |= RC4_STEP<<24;
+                                if (sizeof(RC4_CHUNK)==8)
+                                        {
+                                        otp |= RC4_STEP<<LESHFT(4);
+                                        otp |= RC4_STEP<<LESHFT(5);
+                                        otp |= RC4_STEP<<LESHFT(6);
+                                        otp |= RC4_STEP<<LESHFT(7);
+                                        }
+                                *(RC4_CHUNK *)out = otp^ichunk;
+                                in  += sizeof(RC4_CHUNK);
+                                out += sizeof(RC4_CHUNK);
+                                }
+                        if (len)
+                                {
+                                RC4_CHUNK mask=(RC4_CHUNK)-1, ochunk;
+
+                                ichunk = *(RC4_CHUNK *)in;
+                                ochunk = *(RC4_CHUNK *)out;
+                                otp = 0;
+                                i   = 0;
+                                mask >>= (sizeof(RC4_CHUNK)-len)<<3;
+                                switch (len&(sizeof(RC4_CHUNK)-1))
+                                        {
+                                        case 7: otp  = RC4_STEP,    i+=8;
+                                        case 6: otp |= RC4_STEP<<i, i+=8;
+                                        case 5: otp |= RC4_STEP<<i, i+=8;
+                                        case 4: otp |= RC4_STEP<<i, i+=8;
+                                        case 3: otp |= RC4_STEP<<i, i+=8;
+                                        case 2: otp |= RC4_STEP<<i, i+=8;
+                                        case 1: otp |= RC4_STEP<<i, i+=8;
+                                        case 0: ; /*
+                                                   * it's never the case,
+                                                   * but it has to be here
+                                                   * for ultrix?
+                                                   */
+                                        }
+                                ochunk &= ~mask;
+                                ochunk |= (otp^ichunk) & mask;
+                                *(RC4_CHUNK *)out = ochunk;
+                                }
+                        ctx->x=x;
+                        ctx->y=y;
+                        return;
+                        }
+                }
+#endif
+#define LOOP(in,out) \
+                x=((x+1)&0xff); \
+                tx=d[x]; \
+                y=(tx+y)&0xff; \
+                d[x]=ty=d[y]; \
+                d[y]=tx; \
+                (out) = d[(tx+ty)&0xff]^ (in);
+
+#ifndef RC4_INDEX
+#define RC4_LOOP(a,b,i) LOOP(*((a)++),*((b)++))
+#else
+#define RC4_LOOP(a,b,i) LOOP(a[i],b[i])
+#endif
+
+        i=len>>3;
+        if (i)
+                {
+                for (;;)
+                        {
+                        RC4_LOOP(in,out,0);
+                        RC4_LOOP(in,out,1);
+                        RC4_LOOP(in,out,2);
+                        RC4_LOOP(in,out,3);
+                        RC4_LOOP(in,out,4);
+                        RC4_LOOP(in,out,5);
+                        RC4_LOOP(in,out,6);
+                        RC4_LOOP(in,out,7);
+#ifdef RC4_INDEX
+                        in+=8;
+                        out+=8;
+#endif
+                        if (--i == 0) break;
+                        }
+                }
+        i=len&0x07;
+        if (i)
+                {
+                for (;;)
+                        {
+                        RC4_LOOP(in,out,0); if (--i == 0) break;
+                        RC4_LOOP(in,out,1); if (--i == 0) break;
+                        RC4_LOOP(in,out,2); if (--i == 0) break;
+                        RC4_LOOP(in,out,3); if (--i == 0) break;
+                        RC4_LOOP(in,out,4); if (--i == 0) break;
+                        RC4_LOOP(in,out,5); if (--i == 0) break;
+                        RC4_LOOP(in,out,6); if (--i == 0) break;
+                        }
+                }
+        ctx->x=x;
+        ctx->y=y;
 
-	a = S[x];
-	y = (y + a) & 0xff;
-	b = S[y];
-
-	do {
-		S[y] = a;
-		a = (a + b) & 0xff;
-		S[x] = b;
-		x = (x + 1) & 0xff;
-		ta = S[x];
-		ty = (y + ta) & 0xff;
-		tb = S[ty];
-		*out++ = *in++ ^ S[a];
-		if (--len == 0)
-			break;
-		y = ty;
-		a = ta;
-		b = tb;
-	} while (true);
-
-	ctx->x = x;
-	ctx->y = y;
 }
 
 static void arc4_crypt_one(struct crypto_tfm *tfm, u8 *out, const u8 *in)
